{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(concept of train/test)\n",
    "- Algorithms that can learn from observational data, and can make predictions based on it.\n",
    "### Unsupervised learning\n",
    "- The model isn't given any \"answers\" to learn from; it must make sense of the data just given the observations themselves.\n",
    "- Example: group (cluster) some objects together into 2 different sets. But it's not famous what the \"right\" set is for any object ahead of time.\n",
    "- Do I want a big and small things? Round and square things? Red and blue things? Unsupervised learning could give me any of those results.\n",
    "- If you don't know what you're looking for - you're looking for *latent variables*.\n",
    "- Example: clustering users on a dating site based on their information and behaviour. Perhaps you'll find there are groups of people that emerge that don't conform to your known stereotypes.\n",
    "- Cluster moviews based on their properties. Perhaps our current concepts of genre are outdated?\n",
    "- Analyze the text of product descriptions to find the terms that carry the most meaning for a certain category.\n",
    "-------------------\n",
    "### Supervised Learning\n",
    "- In supervised learning, the data the algorithm \"learns\" from comes with the \"correct\" answers.\n",
    "- The model created is then used to predict the answer for new, unknown values.\n",
    "- Example: you can *train* a model for predicting car prices based on car attributes using historical sales data. The model can then predict the optimal price for new cars that haven't been solf before.\n",
    "-------------------\n",
    "### Evaluating Supervised Learning\n",
    "- If you have a set of training data that includes the value you're trying to predict - you don't have to guess if the resulting model is good or not.\n",
    "- If you have enough training data, you can split it into two parts: a *training* set and a *test* set.\n",
    "- Then train the model using only the training set\n",
    "- Measure (using r-squared or some other metric) the model's accuracy by asking it to predict values for the test set, and compare that to the known, true values.\n",
    "- Usually data is splitted in proportion: Test set - 20% and training set - 80%\n",
    "-------------------\n",
    "### Train/test in practice\n",
    "\n",
    "- Need to ensure both sets are large enough to contain representatives of all the variations and outliers in the data you care about\n",
    "- The data sets must be selected randomly\n",
    "- Train/test is a great way to guard against *overfitting*\n",
    "-------------------\n",
    "### Train/test isn't Infallible\n",
    "\n",
    "- Maybe sample sizes are too small\n",
    "- Or due to random chance train and tests sets look remarkably similar\n",
    "- Overfitting can still happen\n",
    "\n",
    "### K-fold Cross Validation\n",
    "\n",
    "- One way to further protect against overfitting is *K-fold cross validation*\n",
    "- Sounds complicated. But it's a simple idea:\n",
    "    - Split data into K randomly-assigned segments\n",
    "    - Reserve one segment as test data\n",
    "    - Train on each of the remaining K-1 segments and measure their performance against the test set\n",
    "    - Take the average of the K-1 r-squared scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
